# ğŸ§ª Nombre del Taller

## ğŸ“… Fecha
`YYYY-MM-DD` â€“ Fecha de entrega o realizaciÃ³n

---

## ğŸ¯ Objetivo del Taller

Describe brevemente el objetivo del taller: Â¿quÃ© se pretende explorar, aplicar o construir?

---

## ğŸ§  Conceptos Aprendidos

Lista los principales conceptos aplicados:

- [ ] Transformaciones geomÃ©tricas (escala, rotaciÃ³n, traslaciÃ³n)
- [ ] SegmentaciÃ³n de imÃ¡genes
- [ ] Shaders y efectos visuales
- [ ] Entrenamiento de modelos IA
- [ ] ComunicaciÃ³n por gestos o voz
- [ ] Otro: _______________________

---

## ğŸ”§ Herramientas y Entornos

Especifica los entornos usados:

- Python (`opencv-python`, `torch`, `mediapipe`, `diffusers`, etc.)
- Unity (versiÃ³n LTS, XR Toolkit, Shader Graph)
- Three.js / React Three Fiber
- Jupyter / Google Colab

ğŸ“Œ Usa las herramientas segÃºn la [guÃ­a de instalaciÃ³n oficial](./guia_instalacion_entornos_visual.md)

---

## ğŸ“ Estructura del Proyecto

```
YYYY-MM-DD_nombre_taller/
â”œâ”€â”€ entorno/               # python/, unity/, threejs/, colab/
â”œâ”€â”€ datos/                 # imÃ¡genes, audio, modelos, video
â”œâ”€â”€ resultados/            # capturas, mÃ©tricas, gifs
â”œâ”€â”€ README.md
```

ğŸ“ Sigue la estructura de entregas descrita en la [guÃ­a GitLab](./guia_gitlab_computacion_visual.md)

---

## ğŸ§ª ImplementaciÃ³n

Explica el proceso:

### ğŸ”¹ Etapas realizadas
1. PreparaciÃ³n de datos o escena.
2. AplicaciÃ³n de modelo o algoritmo.
3. VisualizaciÃ³n o interacciÃ³n.
4. Guardado de resultados.

### ğŸ”¹ CÃ³digo relevante

Incluye un fragmento que resuma el corazÃ³n del taller:

```python
# SegmentaciÃ³n semÃ¡ntica con DeepLab
output = model(input_tensor)['out']
prediction = output.argmax(1).squeeze().cpu().numpy()
```

---

## ğŸ“Š Resultados Visuales

### ğŸ“Œ Este taller **requiere explÃ­citamente un GIF animado**:

> âœ… Si tu taller lo indica, debes incluir **al menos un GIF** mostrando la ejecuciÃ³n o interacciÃ³n.

- Usa `Peek`, `ScreenToGif`, `OBS`, o desde Python (`imageio`) para generar el GIF.
- **El nombre del GIF debe ser descriptivo del punto que estÃ¡s presentando.**
- Ejemplo correcto:  
  `deteccion_colores_rojo_verde_torres.gif`  
  `movimiento_robot_esquiva_obstaculos_gomez.gif`  
  `shader_gradiente_temporal_lopez.gif`

ğŸ§­ [Ver guÃ­a para crear GIFs](./guia_generar_gif.md)

```markdown
![deteccion](./resultados/deteccion_colores_rojo_verde_torres.gif)
```

> âŒ No se aceptarÃ¡ la entrega si falta el GIF en talleres que lo requieren.

---

## ğŸ§© Prompts Usados

Enumera los prompts utilizados:

```text
"Create a photorealistic image of a robot painting a mural using Stable Diffusion"
"Segment a car and a person using SAM at point (200, 300)"
```

ğŸ“ Usa buenas prÃ¡cticas de prompts segÃºn la [guÃ­a de IA actualizada](./guia_prompts_inteligencias_artificiales_actualizada.md)

---

## ğŸ’¬ ReflexiÃ³n Final

Responde en 2-3 pÃ¡rrafos:

- Â¿QuÃ© aprendiste o reforzaste con este taller?
- Â¿QuÃ© parte fue mÃ¡s compleja o interesante?
- Â¿QuÃ© mejorarÃ­as o quÃ© aplicarÃ­as en futuros proyectos?

---

## ğŸ‘¥ Contribuciones Grupales (si aplica)

Describe exactamente lo que hiciste tÃº:

```markdown
- ProgramÃ© el detector de postura en MediaPipe
- GenerÃ© los GIFs y documentaciÃ³n
- IntegrÃ© el control de voz con visualizaciÃ³n en Unity
```

---

## âœ… Checklist de Entrega

- [x] Carpeta `YYYY-MM-DD_nombre_taller`
- [x] CÃ³digo limpio y funcional
- [x] GIF incluido con nombre descriptivo (si el taller lo requiere)
- [x] Visualizaciones o mÃ©tricas exportadas
- [x] README completo y claro
- [x] Commits descriptivos en inglÃ©s

---